ğŸ¤ AI Voice Assistant

LangGraph â€¢ Llama 3.2 â€¢ IBM Watson â€¢ Flask

An intelligent voice-enabled AI assistant that listens to user speech, understands it using IBM Watson Speech-to-Text, processes queries via LangGraph + Llama 3.2 (Ollama), and replies back using IBM Watson Text-to-Speech â€” all through a modern web interface.

ğŸš€ Features

ğŸ™ï¸ Voice Input (IBM Watson Speech-to-Text)

ğŸ’¬ Text Chat Mode

ğŸ¤– Local LLM (Llama 3.2 via Ollama)

ğŸ§  LangGraph-based Agent Architecture

ğŸ”Š Voice Output (IBM Watson Text-to-Speech)

ğŸŒ Modern Web UI (Tailwind CSS)

ğŸ”„ Session-based Conversation Memory

âš¡ Streaming-ready Backend

ğŸ” Runs Locally â€” No Cloud LLM Cost

ğŸ§  System Architecture
User (Voice / Text)
        â†“
IBM Watson STT
        â†“
Flask API
        â†“
LangGraph Agent
        â†“
Llama 3.2 (Ollama)
        â†“
Flask API
        â†“
IBM Watson TTS
        â†“
User (Voice Output)

ğŸ› ï¸ Tech Stack
Layer	Technology
Frontend	HTML, Tailwind CSS, JavaScript
Backend	Flask, Flask-CORS
AI Orchestration	LangGraph
LLM	Llama 3.2 (Ollama)
Speech-to-Text	IBM Watson STT
Text-to-Speech	IBM Watson TTS
Audio Handling	sounddevice, pygame
ğŸ“ Project Structure
ai-voice-assistant/
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ llm.py        # Ollama LLM config & system prompt
â”‚   â”œâ”€â”€ graph.py      # LangGraph agent definition
â”‚   â”œâ”€â”€ stt.py        # IBM Watson Speech-to-Text
â”‚   â”œâ”€â”€ tts.py        # IBM Watson Text-to-Speech
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html    # Web UI
â”‚
â”œâ”€â”€ app.py            # Flask server & API routes
â”œâ”€â”€ config.py         # API keys & URLs (ignored in git)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸ”§ Prerequisites
1ï¸âƒ£ Install Ollama
https://ollama.com


Pull the model:

ollama pull llama3.2:3b


Verify:

ollama run llama3.2:3b

2ï¸âƒ£ IBM Watson Credentials

Create an IBM Cloud account and enable:

Speech to Text

Text to Speech

Create config.py:

STT_API_KEY = "your_stt_api_key"
STT_URL = "your_stt_url"

TTS_API_KEY = "your_tts_api_key"
TTS_URL = "your_tts_url"


âš ï¸ Never commit config.py to GitHub

ğŸ“¦ Installation
git clone https://github.com/your-username/ai-voice-assistant.git
cd ai-voice-assistant

python -m venv venv
venv\Scripts\activate   # Windows
# source venv/bin/activate  # Linux/Mac

pip install -r requirements.txt

â–¶ï¸ Run the Application
python app.py


Open in browser:

http://localhost:5000

ğŸ—£ï¸ Usage
ğŸ¤ Voice Mode

Click the microphone

Speak clearly

AI replies in voice + text

âŒ¨ï¸ Text Mode

Switch to Text

Type your query

Receive instant response

ğŸ§© How It Works

User speaks â†’ audio captured

IBM Watson STT converts speech to text

LangGraph agent processes the query

Llama 3.2 generates the response

IBM Watson TTS converts response to speech

Audio played in browser

ğŸ›¡ï¸ Key Design Decisions

AIMessage vs SystemMessage separation to ensure correct memory

Single system prompt injection for stability

Local LLM execution for privacy & speed

Threaded TTS to prevent UI blocking

ğŸš§ Known Limitations

Requires microphone permission

IBM API rate limits apply

Streaming UI is optional (backend ready)

ğŸŒ± Future Enhancements

ğŸ” Web Search tool integration

ğŸ“š RAG with PDFs / Knowledge Base

ğŸŒ Multilingual support

â˜ï¸ IBM watsonx.ai deployment

ğŸ“± Mobile-friendly UI

ğŸ‘©â€ğŸ’» Author

Sanchita Malakar
Computer Science Engineer | AI & Web Developer
ğŸ“ India

â€œBuilding practical AI systems, not just demos.â€
